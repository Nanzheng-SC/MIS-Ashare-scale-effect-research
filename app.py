import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import logging
import sys
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
try:
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'Microsoft YaHei']
    plt.rcParams['axes.unicode_minus'] = False
except Exception as e:
    logger.warning(f"è®¾ç½®ä¸­æ–‡å­—ä½“å¤±è´¥: {str(e)}")

# ç¡®ä¿åº”ç”¨åœ¨Streamlit Cloudä¸Šæ­£å¸¸è¿è¡Œçš„è·¯å¾„è®¾ç½®
# è·å–å½“å‰æ–‡ä»¶ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# æ•°æ®ç›®å½•
DATA_DIR = os.path.join(BASE_DIR, 'data')
# ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)
    logger.warning(f"åˆ›å»ºæ•°æ®ç›®å½•: {DATA_DIR}")

# æ£€æŸ¥ç¯å¢ƒï¼ˆå¼€å‘ç¯å¢ƒæˆ–ç”Ÿäº§ç¯å¢ƒï¼‰
IS_LOCAL = os.getenv('STREAMLIT_LOCAL', 'true').lower() == 'true'
logger.info(f"åº”ç”¨è¿è¡Œç¯å¢ƒ: {'æœ¬åœ°å¼€å‘ç¯å¢ƒ' if IS_LOCAL else 'Streamlit Cloudç”Ÿäº§ç¯å¢ƒ'}")

# Streamlité¡µé¢é…ç½®
st.set_page_config(
    page_title="Aè‚¡å¸‚åœºè§„æ¨¡æ•ˆåº”ç ”ç©¶",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å‡½æ•°å®šä¹‰åŒºåŸŸ
def load_group_data():
    """
    åŠ è½½æ‰€æœ‰åˆ†ç»„æ•°æ®
    
    Returns:
        tuple: (åˆ†ç»„æ•°æ®, åˆ†ç»„ä¿¡æ¯)
    """
    try:
        logger.info("å¼€å§‹åŠ è½½åˆ†ç»„æ•°æ®")
        
        # åˆ†ç»„æ˜ å°„ä¿¡æ¯
        group_info = {
            1: {"name": "å°å¸‚å€¼ç»„", "avg_cap": 20.00},
            2: {"name": "æ¬¡å°å¸‚å€¼ç»„", "avg_cap": 57.50},
            3: {"name": "ä¸­ç­‰å¸‚å€¼ç»„", "avg_cap": 180.00},
            4: {"name": "æ¬¡å¤§å¸‚å€¼ç»„", "avg_cap": 380.00},
            5: {"name": "å¤§å¸‚å€¼ç»„", "avg_cap": 850.00}
        }
        
        all_data = []
        # è®¾ç½®æœ€å¤§å…è®¸æ—¥æœŸä¸º2025-12-31
        max_allowed_date = pd.Timestamp('2025-12-31')
        
        # åŠ è½½æ¯ä¸ªåˆ†ç»„çš„æ•°æ®
        for group_id in range(1, 6):
            # æ„å»ºæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ›´å¥å£®çš„è·¯å¾„ç®¡ç†
            group_file = os.path.join(DATA_DIR, f'group_{group_id}_data.csv')
            
            logger.info(f"å°è¯•åŠ è½½åˆ†ç»„ {group_id} æ•°æ®: {group_file}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(group_file):
                logger.error(f"åˆ†ç»„ {group_id} æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {group_file}")
                # åˆ›å»ºç©ºçš„DataFrameç»“æ„ä»¥é¿å…åç»­å¤„ç†é”™è¯¯
                empty_df = pd.DataFrame({
                    'trade_date': pd.Series([], dtype='datetime64[ns]'),
                    'monthly_return': pd.Series([], dtype='float64'),
                    'group_id': [group_id],
                    'group_name': [group_info[group_id]['name']],
                    'avg_market_cap': [group_info[group_id]['avg_cap']]
                })
                all_data.append(empty_df)
                continue
            
            try:
                # ä½¿ç”¨ä½å†…å­˜æ¨¡å¼åŠ è½½æ•°æ®
                df = pd.read_csv(group_file, low_memory=False)
                logger.info(f"æˆåŠŸè¯»å–åˆ†ç»„ {group_id} æ•°æ®æ–‡ä»¶ï¼ŒåŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
                
                # æ·»åŠ åˆ†ç»„ä¿¡æ¯
                df['group_id'] = group_id
                df['group_name'] = group_info[group_id]['name']
                df['avg_market_cap'] = group_info[group_id]['avg_cap']
                
                # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                required_columns = ['monthly_return']
                for col in required_columns:
                    if col not in df.columns:
                        logger.warning(f"åˆ†ç»„ {group_id} æ•°æ®ä¸­ç¼ºå°‘å¿…è¦åˆ—: {col}")
                        df[col] = 0.0
                
                # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®å¹¶éªŒè¯æ—¥æœŸèŒƒå›´
                if 'trade_date' in df.columns:
                    # å¢å¼ºæ—¥æœŸè½¬æ¢é€»è¾‘
                    if not pd.api.types.is_datetime64_any_dtype(df['trade_date']):
                        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºæ•´æ•°æ ¼å¼ï¼ˆYYYYMMDDï¼‰
                        if pd.api.types.is_integer_dtype(df['trade_date']):
                            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d', errors='coerce')
                        else:
                            # å°è¯•å…¶ä»–æ ¼å¼ï¼Œå…è®¸è½¬æ¢å¤±è´¥çš„å€¼ä¸ºNaT
                            df['trade_date'] = pd.to_datetime(df['trade_date'], errors='coerce')
                            
                        # æ£€æŸ¥å¹¶è®°å½•è½¬æ¢å¤±è´¥çš„æƒ…å†µ
                        if df['trade_date'].isna().any():
                            invalid_count = df['trade_date'].isna().sum()
                            logger.warning(f"åˆ†ç»„ {group_id} æ•°æ®ä¸­æœ‰ {invalid_count} æ¡è®°å½•æ—¥æœŸè½¬æ¢å¤±è´¥")
                            # åˆ é™¤è½¬æ¢å¤±è´¥çš„è®°å½•
                            df = df[df['trade_date'].notna()]
                            logger.info(f"åˆ é™¤æ— æ•ˆæ—¥æœŸåï¼Œåˆ†ç»„ {group_id} å‰©ä½™æ•°æ®: {len(df)} æ¡")
                    
                    # è¿‡æ»¤è¶…å‡ºæœ€å¤§å…è®¸æ—¥æœŸçš„æ•°æ®
                    original_len = len(df)
                    df = df[df['trade_date'] <= max_allowed_date]
                    if len(df) < original_len:
                        logger.warning(f"åˆ†ç»„ {group_id} æ•°æ®ä¸­å­˜åœ¨ {original_len - len(df)} æ¡è¶…å‡º2025-12-31çš„è®°å½•ï¼Œå·²è¿‡æ»¤")
                else:
                    logger.warning(f"åˆ†ç»„ {group_id} æ•°æ®ä¸­ä¸å­˜åœ¨ 'trade_date' åˆ—")
                
                # åªä¿ç•™éç©ºæ•°æ®
                if not df.empty:
                    logger.info(f"åˆ†ç»„ {group_id} æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡æœ‰æ•ˆè®°å½•")
                    all_data.append(df)
                else:
                    logger.warning(f"åˆ†ç»„ {group_id} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                    
            except Exception as inner_e:
                logger.error(f"å¤„ç†åˆ†ç»„ {group_id} æ•°æ®æ—¶å‡ºé”™: {str(inner_e)}")
                # åˆ›å»ºç©ºçš„DataFrameç»“æ„ä»¥é¿å…åç»­å¤„ç†é”™è¯¯
                empty_df = pd.DataFrame({
                    'trade_date': pd.Series([], dtype='datetime64[ns]'),
                    'monthly_return': pd.Series([], dtype='float64'),
                    'group_id': [group_id],
                    'group_name': [group_info[group_id]['name']],
                    'avg_market_cap': [group_info[group_id]['avg_cap']]
                })
                all_data.append(empty_df)
        
        # è¿‡æ»¤æ‰ç©ºDataFrame
        valid_data = [df for df in all_data if not df.empty]
        
        if not valid_data:
            logger.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆåˆ†ç»„æ•°æ®")
            return None, group_info
        
        # åˆå¹¶æ‰€æœ‰åˆ†ç»„æ•°æ®
        combined_data = pd.concat(valid_data, ignore_index=True)
        
        # è®°å½•æœ€ç»ˆæ•°æ®çš„æ—¥æœŸèŒƒå›´
        if not combined_data.empty and 'trade_date' in combined_data.columns:
            min_date = combined_data['trade_date'].min()
            max_date = combined_data['trade_date'].max()
            logger.info(f"æˆåŠŸåˆå¹¶ {len(combined_data)} æ¡æ•°æ®è®°å½•")
            logger.info(f"æ•°æ®æ—¥æœŸèŒƒå›´: {min_date} è‡³ {max_date}")
        
        return combined_data, group_info
    
    except Exception as e:
        logger.error(f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None, None

def filter_data_by_time(data, start_date, end_date):
    """
    æ ¹æ®æ—¶é—´èŒƒå›´è¿‡æ»¤æ•°æ®
    
    Args:
        data: åŸå§‹æ•°æ®
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        DataFrame: è¿‡æ»¤åçš„æ•°æ®
    """
    try:
        # æ£€æŸ¥è¾“å…¥æ•°æ®
        if data is None or data.empty:
            logger.warning("è¾“å…¥æ•°æ®ä¸ºç©º")
            return data
            
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œè¿”å›å…¨éƒ¨æ•°æ®
        if start_date is None or end_date is None:
            logger.info("æœªæŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œè¿”å›å…¨éƒ¨æ•°æ®")
            return data
        
        logger.info(f"å¼€å§‹æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤æ•°æ®: {start_date} è‡³ {end_date}")
        
        # ç¡®ä¿trade_dateåˆ—å­˜åœ¨
        if 'trade_date' not in data.columns:
            logger.warning("æ•°æ®ä¸­ä¸å­˜åœ¨'trade_date'åˆ—")
            return data
        
        try:
            # ç¡®ä¿trade_dateåˆ—æ˜¯datetimeç±»å‹
            if not pd.api.types.is_datetime64_any_dtype(data['trade_date']):
                logger.info("è½¬æ¢'trade_date'åˆ—ä¸ºdatetimeç±»å‹")
                if pd.api.types.is_integer_dtype(data['trade_date']):
                    data['trade_date'] = pd.to_datetime(data['trade_date'], format='%Y%m%d', errors='coerce')
                else:
                    data['trade_date'] = pd.to_datetime(data['trade_date'], errors='coerce')
                
                # ç§»é™¤æ— æ•ˆæ—¥æœŸ
                invalid_count = data['trade_date'].isna().sum()
                if invalid_count > 0:
                    logger.warning(f"å‘ç° {invalid_count} æ¡æ— æ•ˆæ—¥æœŸè®°å½•ï¼Œå·²ç§»é™¤")
                    data = data.dropna(subset=['trade_date'])
        except Exception as date_conv_error:
            logger.error(f"æ—¥æœŸç±»å‹è½¬æ¢å¤±è´¥: {str(date_conv_error)}")
            return data
        
        # è½¬æ¢å¼€å§‹å’Œç»“æŸæ—¥æœŸä¸ºæ—¥æœŸå¯¹è±¡ï¼ˆå»é™¤æ—¶é—´ï¼‰
        try:
            start_datetime = pd.to_datetime(start_date).normalize()  # è½¬æ¢ä¸ºå½“å¤©00:00:00
            end_datetime = pd.to_datetime(end_date).normalize()  # è½¬æ¢ä¸ºå½“å¤©00:00:00
            
            # è¿‡æ»¤æ•°æ®ï¼Œä½¿ç”¨æ—¥æœŸéƒ¨åˆ†è¿›è¡Œæ¯”è¾ƒ
            filtered_data = data[(data['trade_date'].dt.date >= start_datetime.date()) & 
                                 (data['trade_date'].dt.date <= end_datetime.date())].copy()
            
            logger.info(f"è¿‡æ»¤åæ•°æ®é‡: {len(filtered_data)}")
            
            # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ•°æ®ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å›åŸå§‹æ•°æ®
            if len(filtered_data) == 0:
                logger.warning(f"æŒ‡å®šæ—¥æœŸèŒƒå›´å†…({start_date}è‡³{end_date})æ²¡æœ‰æ•°æ®")
                # è®°å½•å®é™…æ•°æ®æ—¥æœŸèŒƒå›´ï¼Œå¸®åŠ©è°ƒè¯•
                if not data.empty and 'trade_date' in data.columns:
                    actual_min_date = data['trade_date'].min()
                    actual_max_date = data['trade_date'].max()
                    logger.info(f"å®é™…æ•°æ®æ—¥æœŸèŒƒå›´: {actual_min_date.strftime('%Y-%m-%d')} è‡³ {actual_max_date.strftime('%Y-%m-%d')}")
                return data  # è¿”å›åŸå§‹æ•°æ®è€Œä¸æ˜¯ç©ºDataFrame
                
            return filtered_data
        except Exception as filter_error:
            logger.error(f"æ—¥æœŸè¿‡æ»¤è¿‡ç¨‹ä¸­å‡ºé”™: {str(filter_error)}")
            return data
    except Exception as e:
        logger.error(f"æŒ‰æ—¥æœŸè¿‡æ»¤æ•°æ®æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return data  # å‡ºé”™æ—¶è¿”å›åŸå§‹æ•°æ®è€Œä¸æ˜¯ç©ºDataFrame

def calculate_monthly_returns(data, groups):
    """
    è®¡ç®—æœˆåº¦æ”¶ç›Šç‡
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        
    Returns:
        DataFrame: æœˆåº¦æ”¶ç›Šç‡æ•°æ®
    """
    try:
        # è¿‡æ»¤é€‰æ‹©çš„åˆ†ç»„
        filtered_data = data[data['group_name'].isin(groups)]
        
        # æŒ‰æ—¥æœŸå’Œåˆ†ç»„è®¡ç®—å¹³å‡æœˆåº¦æ”¶ç›Šç‡
        monthly_returns = filtered_data.pivot_table(
            index='trade_date', 
            columns='group_name', 
            values='monthly_return', 
            aggfunc='mean'
        )
        
        # æŒ‰æ—¶é—´æ’åº
        monthly_returns = monthly_returns.sort_index()
        
        return monthly_returns
    except Exception as e:
        logger.error(f"è®¡ç®—æœˆåº¦æ”¶ç›Šç‡å¤±è´¥: {str(e)}")
        return None

def calculate_rolling_annual_return(data, groups, window=12):
    """
    è®¡ç®—æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡ï¼Œå¤„ç†æ—©æœŸæ•°æ®
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        window: æ»šåŠ¨çª—å£å¤§å°
        
    Returns:
        DataFrame: æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡æ•°æ®
    """
    try:
        # è·å–æœˆåº¦æ”¶ç›Šç‡
        monthly_returns = calculate_monthly_returns(data, groups)
        if monthly_returns is None:
            return None
        
        # è®¡ç®—æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡ï¼Œä½¿ç”¨min_periods=1ç¡®ä¿æ—©æœŸæ•°æ®ä¹Ÿèƒ½æ˜¾ç¤º
        # å¯¹äºä¸è¶³çª—å£å¤§å°çš„æ•°æ®ï¼Œä»ç„¶è®¡ç®—ä½†ä½¿ç”¨å¯ç”¨çš„å†å²æ•°æ®
        rolling_annual = ((1 + monthly_returns).rolling(window=window, min_periods=1).apply(
            lambda x: np.prod(1+x)) - 1)
        
        # æ ‡è®°æ•°æ®æœ‰æ•ˆæ€§
        for i in range(min(window-1, len(rolling_annual))):
            # åœ¨æ¯ä¸ªä¸è¶³çª—å£å¤§å°çš„è¡Œæ·»åŠ æ ‡è®°
            if i < window-1:
                for col in rolling_annual.columns:
                    # æˆ‘ä»¬ä¿ç•™è¿™äº›å€¼ä½†åœ¨æ˜¾ç¤ºæ—¶éœ€è¦æ³¨æ„
                    pass
        
        logger.info(f"è®¡ç®—æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡å®Œæˆï¼Œæ•°æ®è¡Œæ•°: {len(rolling_annual)}")
        return rolling_annual
    except Exception as e:
        logger.error(f"è®¡ç®—æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡å¤±è´¥: {str(e)}")
        return None

def calculate_rolling_volatility(data, groups, window=12):
    """
    è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡ï¼Œå¤„ç†æ—©æœŸæ•°æ®
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        window: æ»šåŠ¨çª—å£å¤§å°
        
    Returns:
        DataFrame: æ»šåŠ¨æ³¢åŠ¨ç‡æ•°æ®
    """
    try:
        # è·å–æœˆåº¦æ”¶ç›Šç‡
        monthly_returns = calculate_monthly_returns(data, groups)
        if monthly_returns is None:
            return None
        
        # è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–ï¼‰ï¼Œä½¿ç”¨min_periods=2ç¡®ä¿è‡³å°‘æœ‰2ä¸ªæ•°æ®ç‚¹è®¡ç®—æ ‡å‡†å·®
        rolling_vol = monthly_returns.rolling(window=window, min_periods=2).std() * np.sqrt(12)
        
        logger.info(f"è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡å®Œæˆï¼Œæ•°æ®è¡Œæ•°: {len(rolling_vol)}")
        return rolling_vol
    except Exception as e:
        logger.error(f"è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡å¤±è´¥: {str(e)}")
        return None

def calculate_rolling_sharpe(data, groups, window=12, risk_free_rate=0.02):
    """
    è®¡ç®—æ»šåŠ¨å¤æ™®æ¯”ç‡ï¼Œå¤„ç†æ—©æœŸæ•°æ®å’Œé™¤ä»¥é›¶çš„æƒ…å†µ
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        window: æ»šåŠ¨çª—å£å¤§å°
        risk_free_rate: æ— é£é™©åˆ©ç‡
        
    Returns:
        DataFrame: æ»šåŠ¨å¤æ™®æ¯”ç‡æ•°æ®
    """
    try:
        # è·å–æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡
        rolling_annual = calculate_rolling_annual_return(data, groups, window)
        # è·å–æ»šåŠ¨æ³¢åŠ¨ç‡
        rolling_vol = calculate_rolling_volatility(data, groups, window)
        
        if rolling_annual is None or rolling_vol is None:
            return None
        
        # è®¡ç®—æ»šåŠ¨å¤æ™®æ¯”ç‡ï¼Œå¤„ç†é™¤ä»¥é›¶çš„æƒ…å†µ
        # ä½¿ç”¨np.whereé¿å…é™¤ä»¥é›¶
        rolling_sharpe = np.where(
            rolling_vol == 0,
            np.nan,  # å½“æ³¢åŠ¨ç‡ä¸º0æ—¶è®¾ä¸ºNaN
            (rolling_annual - risk_free_rate) / rolling_vol
        )
        
        # è½¬æ¢å›DataFrameæ ¼å¼
        rolling_sharpe_df = pd.DataFrame(
            rolling_sharpe, 
            index=rolling_annual.index, 
            columns=rolling_annual.columns
        )
        
        logger.info(f"è®¡ç®—æ»šåŠ¨å¤æ™®æ¯”ç‡å®Œæˆï¼Œæ•°æ®è¡Œæ•°: {len(rolling_sharpe_df)}")
        return rolling_sharpe_df
    except Exception as e:
        logger.error(f"è®¡ç®—æ»šåŠ¨å¤æ™®æ¯”ç‡å¤±è´¥: {str(e)}")
        return None

def calculate_time_series_metrics(data, groups, metric=None, rolling_window=12):
    """
    è®¡ç®—æ—¶é—´åºåˆ—æŒ‡æ ‡
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        metric: æŒ‡æ ‡ç±»å‹ ('monthly_return', 'annual_return', 'volatility', 'sharpe')ï¼Œå¦‚æœä¸ºNoneåˆ™è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ç”¨äºæ€»è¯„åˆ†
        rolling_window: æ»šåŠ¨çª—å£å¤§å°
        
    Returns:
        DataFrame: å•ä¸ªæŒ‡æ ‡æ—¶è¿”å›DataFrameï¼Œè®¡ç®—æ‰€æœ‰æŒ‡æ ‡æ—¶è¿”å›åŒ…å«å„æŒ‡æ ‡ç»“æœçš„å­—å…¸
    """
    if metric is not None:
        # å•ä¸ªæŒ‡æ ‡è®¡ç®—æ¨¡å¼
        if metric == 'monthly_return':
            return calculate_monthly_returns(data, groups)
        elif metric == 'annual_return':
            return calculate_rolling_annual_return(data, groups, rolling_window)
        elif metric == 'volatility':
            return calculate_rolling_volatility(data, groups, rolling_window)
        elif metric == 'sharpe':
            return calculate_rolling_sharpe(data, groups, rolling_window)
        else:
            logger.error(f"æœªçŸ¥çš„æŒ‡æ ‡ç±»å‹: {metric}")
            return None
    else:
        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ç”¨äºæ€»è¯„åˆ†
        try:
            # è®¡ç®—å„ä¸ªæŒ‡æ ‡
            monthly_returns = calculate_monthly_returns(data, groups)
            annual_returns = calculate_rolling_annual_return(data, groups, rolling_window)
            volatility = calculate_rolling_volatility(data, groups, rolling_window)
            sharpe = calculate_rolling_sharpe(data, groups, rolling_window)
            
            # è®¡ç®—æ€»è¯„åˆ†
            total_scores = None
            if monthly_returns is not None and annual_returns is not None and volatility is not None and sharpe is not None:
                # ä½¿ç”¨åŠ æƒå¹³å‡è®¡ç®—æ€»è¯„åˆ†ï¼ˆæ”¶ç›Šç‡30%ã€æ³¢åŠ¨ç‡20%ã€å¤æ™®æ¯”ç‡50%ï¼‰
                # é¦–å…ˆè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œå°†å„æŒ‡æ ‡æ˜ å°„åˆ°0-100åˆ†
                
                # ç¡®ä¿æ‰€æœ‰æŒ‡æ ‡æœ‰ç›¸åŒçš„ç´¢å¼•å’Œåˆ—
                idx = monthly_returns.index
                cols = monthly_returns.columns
                
                # æ ‡å‡†åŒ–å¹´åŒ–æ”¶ç›Šç‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
                annual_min, annual_max = annual_returns.min().min(), annual_returns.max().max()
                annual_score = 0
                if annual_max > annual_min:
                    annual_score = 100 * (annual_returns - annual_min) / (annual_max - annual_min)
                
                # æ ‡å‡†åŒ–æ³¢åŠ¨ç‡ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
                vol_min, vol_max = volatility.min().min(), volatility.max().max()
                vol_score = 100
                if vol_max > vol_min:
                    vol_score = 100 * (vol_max - volatility) / (vol_max - vol_min)
                
                # æ ‡å‡†åŒ–å¤æ™®æ¯”ç‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
                sharpe_min, sharpe_max = sharpe.min().min(), sharpe.max().max()
                sharpe_score = 0
                if sharpe_max > sharpe_min:
                    sharpe_score = 100 * (sharpe - sharpe_min) / (sharpe_max - sharpe_min)
                
                # è®¡ç®—åŠ æƒæ€»è¯„åˆ†
                total_scores = 0.3 * annual_score + 0.2 * vol_score + 0.5 * sharpe_score
            
            return {
                'monthly_returns': monthly_returns,
                'annual_returns': annual_returns,
                'volatility': volatility,
                'sharpe': sharpe,
                'total_scores': total_scores
            }
        except Exception as e:
            logger.error(f"è®¡ç®—æ€»è¯„åˆ†æ—¶å‡ºé”™: {str(e)}")
            return {
                'monthly_returns': None,
                'annual_returns': None,
                'volatility': None,
                'sharpe': None,
                'total_scores': None
            }

# å·²å°†æ€»è¯„åˆ†è®¡ç®—æ•´åˆåˆ°ç°æœ‰çš„calculate_time_series_metricså‡½æ•°ä¸­

def calculate_total_scores(metrics, groups):
    """
    è®¡ç®—æ€»è¯„åˆ†ï¼ŒåŸºäºå¹´åŒ–æ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡å’Œå¤æ™®æ¯”ç‡
    
    Args:
        metrics: åŒ…å«å„ç§æŒ‡æ ‡çš„å­—å…¸
        groups: è¦åˆ†æçš„åˆ†ç»„
        
    Returns:
        DataFrame: å„åˆ†ç»„çš„æ€»è¯„åˆ†
    """
    try:
        # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æŒ‡æ ‡éƒ½å­˜åœ¨
        if not all(key in metrics and metrics[key] is not None for key in ['rolling_annual', 'rolling_vol', 'rolling_sharpe']):
            logger.warning("ç¼ºå°‘è®¡ç®—æ€»è¯„åˆ†æ‰€éœ€çš„æŒ‡æ ‡")
            return None
        
        # å¤åˆ¶æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        annual_returns = metrics['rolling_annual'].copy()
        volatility = metrics['rolling_vol'].copy()
        sharpe = metrics['rolling_sharpe'].copy()
        
        # åˆå§‹åŒ–æ€»è¯„åˆ†DataFrame
        scores = pd.DataFrame(index=annual_returns.index, columns=groups)
        
        # ä¸ºæ¯ä¸ªæ—¶é—´ç‚¹è®¡ç®—è¯„åˆ†
        for date in annual_returns.index:
            # è·å–å½“å‰æ—¥æœŸçš„æŒ‡æ ‡å€¼
            annual_values = annual_returns.loc[date].dropna()
            vol_values = volatility.loc[date].dropna()
            sharpe_values = sharpe.loc[date].dropna()
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆæƒé‡ï¼šæ”¶ç›Šç‡30%ï¼Œæ³¢åŠ¨ç‡20%ï¼Œå¤æ™®æ¯”ç‡50%ï¼‰
            # å¯¹æ¯ä¸ªåˆ†ç»„åˆ†åˆ«è®¡ç®—
            for group in groups:
                if group in annual_values.index and group in vol_values.index and group in sharpe_values.index:
                    # å½’ä¸€åŒ–å¤„ç†
                    # æ”¶ç›Šç‡å¾—åˆ†ï¼šå°†æ”¶ç›Šç‡è½¬æ¢ä¸º0-100çš„å¾—åˆ†
                    # æ³¢åŠ¨ç‡å¾—åˆ†ï¼šä½æ³¢åŠ¨ç‡å¾—é«˜åˆ†ï¼ŒèŒƒå›´0-100
                    # å¤æ™®æ¯”ç‡å¾—åˆ†ï¼šè½¬æ¢ä¸º0-100çš„å¾—åˆ†
                    
                    # è®¡ç®—æ”¶ç›Šç‡å¾—åˆ†ï¼ˆåŸºäºå†å²æœ€å¤§å€¼å’Œæœ€å°å€¼ï¼‰
                    hist_annual_min = annual_returns[group].min()
                    hist_annual_max = annual_returns[group].max()
                    annual_score = 0
                    if hist_annual_max > hist_annual_min:
                        annual_score = 100 * (annual_values[group] - hist_annual_min) / (hist_annual_max - hist_annual_min)
                    
                    # è®¡ç®—æ³¢åŠ¨ç‡å¾—åˆ†ï¼ˆä½æ³¢åŠ¨ç‡å¾—é«˜åˆ†ï¼‰
                    hist_vol_min = volatility[group].min()
                    hist_vol_max = volatility[group].max()
                    vol_score = 0
                    if hist_vol_max > hist_vol_min:
                        # æ³¢åŠ¨ç‡è¶Šä½å¾—åˆ†è¶Šé«˜
                        vol_score = 100 * (1 - (vol_values[group] - hist_vol_min) / (hist_vol_max - hist_vol_min))
                    
                    # è®¡ç®—å¤æ™®æ¯”ç‡å¾—åˆ†
                    hist_sharpe_min = sharpe[group].min()
                    hist_sharpe_max = sharpe[group].max()
                    sharpe_score = 0
                    if hist_sharpe_max > hist_sharpe_min:
                        sharpe_score = 100 * (sharpe_values[group] - hist_sharpe_min) / (hist_sharpe_max - hist_sharpe_min)
                    
                    # è®¡ç®—æ€»è¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
                    scores.loc[date, group] = 0.3 * annual_score + 0.2 * vol_score + 0.5 * sharpe_score
        
        # å¤„ç†å¯èƒ½çš„NaNå€¼
        scores = scores.fillna(0)
        
        logger.info(f"è®¡ç®—æ€»è¯„åˆ†å®Œæˆï¼Œæ•°æ®è¡Œæ•°: {len(scores)}")
        return scores
    except Exception as e:
        logger.error(f"è®¡ç®—æ€»è¯„åˆ†å¤±è´¥: {str(e)}")
        return None

def plot_time_series(ax, data, title, ylabel, is_percentage=False):
    """
    ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾è¡¨
    
    Args:
        ax: matplotlibè½´å¯¹è±¡
        data: è¦ç»˜åˆ¶çš„æ•°æ®
        title: å›¾è¡¨æ ‡é¢˜
        ylabel: Yè½´æ ‡ç­¾
        is_percentage: æ˜¯å¦æŒ‰ç™¾åˆ†æ¯”æ˜¾ç¤º
    """
    try:
        # ä¸ºæ¯ä¸ªç»„åˆ«ç»˜åˆ¶æŠ˜çº¿
        for column in data.columns:
            ax.plot(data.index, data[column], marker='o', markersize=3, linewidth=2, label=column)
        
        # è®¾ç½®å›¾è¡¨å±æ€§
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.set_xlabel('æ—¥æœŸ', fontsize=12)
        ax.set_ylabel(ylabel, fontsize=12)
        ax.grid(True, linestyle='--', alpha=0.7)
        ax.legend(title='å¸‚å€¼ç»„åˆ«', fontsize=10)
        
        # è®¾ç½®æ—¥æœŸæ ¼å¼
        fig = ax.get_figure()
        fig.autofmt_xdate()
        
        # å¦‚æœæ˜¯ç™¾åˆ†æ¯”æ ¼å¼ï¼Œè®¾ç½®Yè½´æ ¼å¼
        if is_percentage:
            ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0%}'))
            
    except Exception as e:
        logger.error(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {str(e)}")
        raise

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Aè‚¡å¸‚åœºè§„æ¨¡æ•ˆåº”ç ”ç©¶",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ‡é¢˜
st.title("Aè‚¡å¸‚åœºè§„æ¨¡æ•ˆåº”ç ”ç©¶")
st.markdown("""
    æœ¬å·¥å…·ç”¨äºå¯è§†åŒ–åˆ†æAè‚¡å¸‚åœºä¸­ä¸åŒå¸‚å€¼ç»„åˆ«è‚¡ç¥¨çš„è¡¨ç°.
    æ‚¨å¯ä»¥é€‰æ‹©ä¸åŒçš„å¸‚å€¼ç»„åˆ«ã€æ—¶é—´èŒƒå›´å’ŒæŒ‡æ ‡è¿›è¡Œäº¤äº’å¼åˆ†æ.
""")

# ä¾§è¾¹æ  - ç”¨æˆ·è¾“å…¥åŒºåŸŸ
with st.sidebar:
    st.header("å‚æ•°è®¾ç½®")
    
    # åŠ è½½åˆ†ç»„ä¿¡æ¯
    _, group_info = load_group_data()
    
    # åˆ†ç»„é€‰æ‹©åŠŸèƒ½
    st.subheader("é€‰æ‹©åˆ†ç»„")
    if group_info:
        # æå–æ‰€æœ‰åˆ†ç»„åç§°
        all_groups = [group_info[group_id]['name'] for group_id in sorted(group_info.keys())]
        
        # åˆ†ç»„å¤šé€‰æ§ä»¶ï¼Œæ”¹ä¸ºå‹¾é€‰å½¢å¼
        st.markdown("é€‰æ‹©è¦åˆ†æçš„å¸‚å€¼ç»„åˆ«ï¼š")
        selected_groups = []
        cols = st.columns(2)
        for i, group_name in enumerate(all_groups):
            col_idx = i % 2
            if cols[col_idx].checkbox(group_name, value=True, help=f"æ˜¾ç¤º{group_name}çš„è¡¨ç°æ•°æ®åŠåˆ†æ"):
                selected_groups.append(group_name)
        
        # æ˜¾ç¤ºå·²é€‰åˆ†ç»„çš„å¹³å‡å¸‚å€¼ä¿¡æ¯
        if selected_groups:
            st.write("\nå·²é€‰åˆ†ç»„ä¿¡æ¯ï¼š")
            for group_name in selected_groups:
                # æ‰¾åˆ°å¯¹åº”çš„åˆ†ç»„ID
                group_id = next(gid for gid, info in group_info.items() if info['name'] == group_name)
                avg_cap = group_info[group_id]['avg_cap']
                st.write(f"- {group_name}: å¹³å‡å¸‚å€¼çº¦ {avg_cap} äº¿å…ƒ")
    else:
        st.warning("æ— æ³•åŠ è½½åˆ†ç»„ä¿¡æ¯")
        selected_groups = []
    
    # æ—¶é—´èŒƒå›´é€‰æ‹©
    st.subheader("é€‰æ‹©æ—¶é—´èŒƒå›´")
    
    # é¢„è®¾æ—¶é—´èŒƒå›´é€‰é¡¹
    time_period_options = {
        "å…¨éƒ¨æ•°æ®": None,
        "è¿‘1å¹´": 365,
        "è¿‘3å¹´": 1095,
        "è¿‘5å¹´": 1825
    }
    
    # æ—¶é—´èŒƒå›´é€‰æ‹©å™¨
    selected_time_period = st.selectbox(
        "å¿«é€Ÿé€‰æ‹©æ—¶é—´èŒƒå›´ï¼š",
        options=list(time_period_options.keys()),
        index=0,
        help="å¿«é€Ÿé€‰æ‹©åˆ†æçš„æ—¶é—´åŒºé—´ï¼Œå½±å“æ•°æ®è¦†ç›–èŒƒå›´"
    )
    
    # è‡ªå®šä¹‰æ—¥æœŸé€‰æ‹©å™¨
    use_custom_date = st.checkbox("ä½¿ç”¨è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´", value=False, help="å¯ç”¨è‡ªå®šä¹‰æ—¥æœŸé€‰æ‹©ï¼Œå¯ç²¾ç¡®æ§åˆ¶åˆ†æçš„èµ·å§‹å’Œç»“æŸæ—¶é—´")
    
    # åˆå§‹åŒ–æ—¥æœŸå˜é‡
    start_date = None
    end_date = None
    
    # å¦‚æœæœ‰æ•°æ®ï¼Œè·å–æ•°æ®çš„æ—¥æœŸèŒƒå›´
    data, _ = load_group_data()
    min_date = None
    max_date = None
    
    if data is not None and not data.empty:
        min_date = data['trade_date'].min().date()
        max_date = data['trade_date'].max().date()
    else:
        # é»˜è®¤æ—¥æœŸèŒƒå›´
        max_date = pd.Timestamp.now().date()
        min_date = max_date - pd.Timedelta(days=365*5)
    
    # è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´é€‰æ‹©
    if use_custom_date:
        start_date = st.date_input(
            "å¼€å§‹æ—¥æœŸï¼š",
            value=min_date,
            min_value=min_date,
            max_value=max_date
        )
        end_date = st.date_input(
            "ç»“æŸæ—¥æœŸï¼š",
            value=max_date,
            min_value=min_date,
            max_value=max_date
        )
    else:
        # æ ¹æ®é¢„è®¾é€‰é¡¹è®¡ç®—æ—¥æœŸèŒƒå›´
        if time_period_options[selected_time_period] is not None:
            days = time_period_options[selected_time_period]
            end_date = max_date
            start_date = end_date - pd.Timedelta(days=days)
            # ç¡®ä¿ä¸è¶…è¿‡æ•°æ®çš„æœ€å°æ—¥æœŸ
            if start_date < min_date:
                start_date = min_date
        else:
            # å…¨éƒ¨æ•°æ®
            start_date = min_date
            end_date = max_date
    
    # æŒ‡æ ‡é€‰æ‹©
    st.subheader("é€‰æ‹©åˆ†ææŒ‡æ ‡")
    metrics_options = {
        "æœˆåº¦æ”¶ç›Šç‡": "monthly_return",
        "æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡": "annual_return",
        "æ»šåŠ¨æ³¢åŠ¨ç‡": "volatility",
        "æ»šåŠ¨å¤æ™®æ¯”ç‡": "sharpe"
    }
    
    # æŒ‡æ ‡è§£é‡Šå­—å…¸
    metric_explanations = {
        "æœˆåº¦æ”¶ç›Šç‡": "åæ˜ æ¯æœˆæŠ•èµ„å›æŠ¥ç™¾åˆ†æ¯”ï¼Œç›´æ¥å±•ç¤ºçŸ­æœŸæ”¶ç›Šè¡¨ç°",
        "æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡": "åŸºäºæŒ‡å®šçª—å£çš„æœˆåº¦æ”¶ç›Šç‡è®¡ç®—çš„å¹´åŒ–å›æŠ¥ç‡ï¼Œè¡¡é‡é•¿æœŸæ”¶ç›Šèƒ½åŠ›",
        "æ»šåŠ¨æ³¢åŠ¨ç‡": "åæ˜ ä»·æ ¼å˜åŠ¨çš„å‰§çƒˆç¨‹åº¦ï¼Œè¡¡é‡æŠ•èµ„é£é™©æ°´å¹³",
        "æ»šåŠ¨å¤æ™®æ¯”ç‡": "è¡¡é‡é£é™©è°ƒæ•´åçš„æŠ•èµ„å›æŠ¥ï¼Œç»¼åˆè€ƒè™‘æ”¶ç›Šå’Œé£é™©"
    }
    
    # æŒ‡æ ‡é€‰æ‹©ï¼Œæ”¹ä¸ºå‹¾é€‰å½¢å¼
    st.markdown("é€‰æ‹©è¦åˆ†æçš„æŒ‡æ ‡ï¼š")
    selected_metrics = []
    for metric_display in list(metrics_options.keys()):
        default_selected = metric_display in ["æœˆåº¦æ”¶ç›Šç‡", "æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡"]
        if st.checkbox(metric_display, value=default_selected, help=f"{metric_display}ï¼š{metric_explanations[metric_display]}"):
            selected_metrics.append(metric_display)
    
    # æ»šåŠ¨çª—å£å¤§å°é€‰æ‹©
    st.subheader("æ»šåŠ¨çª—å£è®¾ç½®")
    window_size = st.slider(
        "æ»šåŠ¨çª—å£å¤§å°ï¼ˆæœˆï¼‰ï¼š",
        min_value=3,
        max_value=36,
        value=12,
        step=1,
        help="è®¡ç®—æ»šåŠ¨æŒ‡æ ‡çš„æ—¶é—´çª—å£ï¼Œçª—å£è¶Šå¤§ç»“æœè¶Šç¨³å®šä½†å¯¹å˜åŒ–ååº”è¶Šæ…¢ï¼Œçª—å£è¶Šå°ç»“æœè¶Šæ•æ„Ÿä½†æ³¢åŠ¨è¶Šå¤§")
    
    # å›¾è¡¨è®¾ç½®è¯´æ˜
    st.subheader("å›¾è¡¨ä½¿ç”¨æç¤º")
    st.info("ğŸ’¡ å›¾è¡¨æ”¯æŒä½¿ç”¨é¼ æ ‡æ»šè½®æ”¾å¤§ç¼©å°ï¼Œæ‹–åŠ¨å¹³ç§»æŸ¥çœ‹ç»†èŠ‚")
    
    st.divider()
    st.info("é€‰æ‹©å‚æ•°åï¼Œç‚¹å‡»åˆ†ææŒ‰é’®æŸ¥çœ‹ç»“æœ")

# ä¸»å†…å®¹åŒº
main_content = st.container()

# å‡½æ•°å®šä¹‰åŒºåŸŸ

def calculate_monthly_returns(data, groups):
    """
    è®¡ç®—æœˆåº¦æ”¶ç›Šç‡
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        
    Returns:
        DataFrame: æœˆåº¦æ”¶ç›Šç‡æ•°æ®
    """
    try:
        # è¿‡æ»¤é€‰æ‹©çš„åˆ†ç»„
        filtered_data = data[data['group_name'].isin(groups)]
        
        # æŒ‰æ—¥æœŸå’Œåˆ†ç»„è®¡ç®—å¹³å‡æœˆåº¦æ”¶ç›Šç‡
        monthly_returns = filtered_data.pivot_table(
            index='trade_date', 
            columns='group_name', 
            values='monthly_return', 
            aggfunc='mean'
        )
        
        # æŒ‰æ—¶é—´æ’åº
        monthly_returns = monthly_returns.sort_index()
        
        return monthly_returns
    except Exception as e:
        logger.error(f"è®¡ç®—æœˆåº¦æ”¶ç›Šç‡å¤±è´¥: {str(e)}")
        return None

def calculate_rolling_annual_return(data, groups, window=12):
    """
    è®¡ç®—æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        window: æ»šåŠ¨çª—å£å¤§å°
        
    Returns:
        DataFrame: æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡æ•°æ®
    """
    try:
        # è·å–æœˆåº¦æ”¶ç›Šç‡
        monthly_returns = calculate_monthly_returns(data, groups)
        if monthly_returns is None:
            return None
        
        # è®¡ç®—æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡
        rolling_annual = ((1 + monthly_returns).rolling(window=window).apply(
            lambda x: np.prod(1+x)) - 1)
        
        return rolling_annual
    except Exception as e:
        logger.error(f"è®¡ç®—æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡å¤±è´¥: {str(e)}")
        return None

def calculate_rolling_volatility(data, groups, window=12):
    """
    è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        window: æ»šåŠ¨çª—å£å¤§å°
        
    Returns:
        DataFrame: æ»šåŠ¨æ³¢åŠ¨ç‡æ•°æ®
    """
    try:
        # è·å–æœˆåº¦æ”¶ç›Šç‡
        monthly_returns = calculate_monthly_returns(data, groups)
        if monthly_returns is None:
            return None
        
        # è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–ï¼‰
        rolling_vol = monthly_returns.rolling(window=window).std() * np.sqrt(12)
        
        return rolling_vol
    except Exception as e:
        logger.error(f"è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡å¤±è´¥: {str(e)}")
        return None

def calculate_rolling_sharpe(data, groups, window=12, risk_free_rate=0.02):
    """
    è®¡ç®—æ»šåŠ¨å¤æ™®æ¯”ç‡
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        window: æ»šåŠ¨çª—å£å¤§å°
        risk_free_rate: æ— é£é™©åˆ©ç‡
        
    Returns:
        DataFrame: æ»šåŠ¨å¤æ™®æ¯”ç‡æ•°æ®
    """
    try:
        # è·å–æ»šåŠ¨å¹´åŒ–æ”¶ç›Šç‡
        rolling_annual = calculate_rolling_annual_return(data, groups, window)
        # è·å–æ»šåŠ¨æ³¢åŠ¨ç‡
        rolling_vol = calculate_rolling_volatility(data, groups, window)
        
        if rolling_annual is None or rolling_vol is None:
            return None
        
        # è®¡ç®—æ»šåŠ¨å¤æ™®æ¯”ç‡
        rolling_sharpe = (rolling_annual - risk_free_rate) / rolling_vol
        
        return rolling_sharpe
    except Exception as e:
        logger.error(f"è®¡ç®—æ»šåŠ¨å¤æ™®æ¯”ç‡å¤±è´¥: {str(e)}")
        return None

def calculate_time_series_metrics(data, groups, metric=None, rolling_window=12):
    """
    è®¡ç®—æ—¶é—´åºåˆ—æŒ‡æ ‡
    
    Args:
        data: åˆ†ç»„æ•°æ®
        groups: è¦åˆ†æçš„åˆ†ç»„
        metric: æŒ‡æ ‡ç±»å‹ ('monthly_return', 'annual_return', 'volatility', 'sharpe')ï¼Œä¸ºNoneæ—¶è¿”å›æ‰€æœ‰æŒ‡æ ‡
        rolling_window: æ»šåŠ¨çª—å£å¤§å°
        
    Returns:
        DataFrameæˆ–dict: å•ä¸ªæŒ‡æ ‡è¿”å›DataFrameï¼Œå¤šä¸ªæŒ‡æ ‡è¿”å›åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„å­—å…¸
    """
    # å¦‚æœæŒ‡å®šäº†å…·ä½“æŒ‡æ ‡ï¼Œåªè¿”å›è¯¥æŒ‡æ ‡
    if metric:
        if metric == 'monthly_return':
            return calculate_monthly_returns(data, groups)
        elif metric == 'annual_return':
            return calculate_rolling_annual_return(data, groups, rolling_window)
        elif metric == 'volatility':
            return calculate_rolling_volatility(data, groups, rolling_window)
        elif metric == 'sharpe':
            return calculate_rolling_sharpe(data, groups, rolling_window)
        else:
            return None
    
    # å¦‚æœmetricä¸ºNoneï¼Œè®¡ç®—æ‰€æœ‰æŒ‡æ ‡å¹¶è¿”å›å­—å…¸
    try:
        # è®¡ç®—æ‰€æœ‰åŸºç¡€æŒ‡æ ‡
        monthly_returns = calculate_monthly_returns(data, groups)
        rolling_annual = calculate_rolling_annual_return(data, groups, rolling_window)
        rolling_vol = calculate_rolling_volatility(data, groups, rolling_window)
        rolling_sharpe = calculate_rolling_sharpe(data, groups, rolling_window)
        
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        result = {
            'monthly_returns': monthly_returns,
            'rolling_annual': rolling_annual,
            'rolling_vol': rolling_vol,
            'rolling_sharpe': rolling_sharpe,
            'total_scores': None  # åˆå§‹åŒ–æ€»è¯„åˆ†
        }
        
        # åªæœ‰å½“æ‰€æœ‰å¿…è¦çš„æŒ‡æ ‡éƒ½éç©ºæ—¶æ‰è®¡ç®—æ€»è¯„åˆ†
        if (monthly_returns is not None and rolling_annual is not None and 
            rolling_vol is not None and rolling_sharpe is not None):
            
            # åˆå§‹åŒ–æ€»è¯„åˆ†DataFrame
            scores = pd.DataFrame(index=rolling_annual.index, columns=groups)
            
            # ä¸ºæ¯ä¸ªæ—¶é—´ç‚¹è®¡ç®—è¯„åˆ†
            for date in rolling_annual.index:
                # è·å–å½“å‰æ—¥æœŸçš„æŒ‡æ ‡å€¼
                annual_values = rolling_annual.loc[date].dropna()
                vol_values = rolling_vol.loc[date].dropna()
                sharpe_values = rolling_sharpe.loc[date].dropna()
                
                # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆæƒé‡ï¼šæ”¶ç›Šç‡30%ï¼Œæ³¢åŠ¨ç‡20%ï¼Œå¤æ™®æ¯”ç‡50%ï¼‰
                # å¯¹æ¯ä¸ªåˆ†ç»„åˆ†åˆ«è®¡ç®—
                for group in groups:
                    if group in annual_values.index and group in vol_values.index and group in sharpe_values.index:
                        try:
                            # è®¡ç®—æ”¶ç›Šç‡å¾—åˆ†ï¼ˆåŸºäºå†å²æœ€å¤§å€¼å’Œæœ€å°å€¼ï¼‰
                                hist_annual_min = rolling_annual[group].min()
                                hist_annual_max = rolling_annual[group].max()
                                annual_score = 0
                                if hist_annual_max > hist_annual_min:
                                    # æ”¶ç›Šç‡è¶Šé«˜è¶Šå¥½ï¼Œè½¬æ¢ä¸º0-100åˆ†
                                    annual_score = 100 * (annual_values[group] - hist_annual_min) / (hist_annual_max - hist_annual_min)
                                
                                # è®¡ç®—æ³¢åŠ¨ç‡å¾—åˆ†ï¼ˆåŸºäºå†å²æœ€å¤§å€¼å’Œæœ€å°å€¼ï¼‰
                                hist_vol_min = rolling_vol[group].min()
                                hist_vol_max = rolling_vol[group].max()
                                vol_score = 0
                                if hist_vol_max > hist_vol_min:
                                    # æ³¢åŠ¨ç‡è¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥è¿›è¡Œåå‘è¯„åˆ†
                                    vol_score = 100 * (1 - (vol_values[group] - hist_vol_min) / (hist_vol_max - hist_vol_min))
                                    # é¢å¤–å¤„ç†ï¼šå¯¹äºæé«˜çš„æ³¢åŠ¨ç‡ç»™äºˆæ›´ä½çš„åˆ†æ•°
                                    if vol_values[group] > hist_vol_min + 0.75 * (hist_vol_max - hist_vol_min):
                                        vol_score = vol_score * 0.7  # å¯¹é«˜æ³¢åŠ¨è¿›è¡Œæƒ©ç½š
                                
                                # è®¡ç®—å¤æ™®æ¯”ç‡å¾—åˆ†
                                hist_sharpe_min = rolling_sharpe[group].min()
                                hist_sharpe_max = rolling_sharpe[group].max()
                                sharpe_score = 0
                                if hist_sharpe_max > hist_sharpe_min:
                                    # å¤æ™®æ¯”ç‡è¶Šé«˜è¶Šå¥½ï¼Œè½¬æ¢ä¸º0-100åˆ†
                                    sharpe_score = 100 * (sharpe_values[group] - hist_sharpe_min) / (hist_sharpe_max - hist_sharpe_min)
                                    # é¢å¤–å¤„ç†ï¼šå¯¹äºè´Ÿçš„å¤æ™®æ¯”ç‡ç»™äºˆæ›´ä½çš„åˆ†æ•°
                                    if sharpe_values[group] < 0:
                                        sharpe_score = sharpe_score * 0.5  # å¯¹è´Ÿå¤æ™®æ¯”ç‡è¿›è¡Œæƒ©ç½š
                                
                                # è®¡ç®—æ€»è¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
                                # æƒé‡åˆ†é…ï¼šæ”¶ç›Šç‡(30%)ã€æ³¢åŠ¨ç‡(20%)ã€å¤æ™®æ¯”ç‡(50%)
                                # åŸºäºæŠ•èµ„ä»·å€¼è¯„ä¼°åŸåˆ™ï¼šé£é™©è°ƒæ•´å›æŠ¥(å¤æ™®æ¯”ç‡)æœ€é‡è¦ï¼Œå…¶æ¬¡æ˜¯ç»å¯¹æ”¶ç›Šï¼Œæœ€åæ˜¯é£é™©æ§åˆ¶
                                scores.loc[date, group] = 0.3 * annual_score + 0.2 * vol_score + 0.5 * sharpe_score
                        except Exception as e:
                            logger.error(f"è®¡ç®—{group}çš„è¯„åˆ†æ—¶å‡ºé”™: {str(e)}")
                            scores.loc[date, group] = 0
            
            # å¤„ç†å¯èƒ½çš„NaNå€¼
            scores = scores.fillna(0)
            result['total_scores'] = scores
            logger.info(f"è®¡ç®—æ€»è¯„åˆ†å®Œæˆï¼Œæ•°æ®è¡Œæ•°: {len(scores)}")
        
        return result
    except Exception as e:
        logger.error(f"è®¡ç®—æŒ‡æ ‡é›†æ—¶å‡ºé”™: {str(e)}")
        return None
        return calculate_rolling_sharpe(data, groups, rolling_window)
    else:
        logger.error(f"æœªçŸ¥çš„æŒ‡æ ‡ç±»å‹: {metric}")
        return None

def plot_time_series(ax, data, title, ylabel, is_percentage=False):
    """
    ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾è¡¨
    
    Args:
        ax: matplotlibè½´å¯¹è±¡
        data: è¦ç»˜åˆ¶çš„æ•°æ®
        title: å›¾è¡¨æ ‡é¢˜
        ylabel: Yè½´æ ‡ç­¾
        is_percentage: æ˜¯å¦æŒ‰ç™¾åˆ†æ¯”æ˜¾ç¤º
    """
    try:
        # ä¸ºæ¯ä¸ªç»„åˆ«ç»˜åˆ¶æŠ˜çº¿
        for column in data.columns:
            ax.plot(data.index, data[column], marker='o', markersize=3, linewidth=2, label=column)
        
        # è®¾ç½®å›¾è¡¨å±æ€§
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.set_xlabel('æ—¥æœŸ', fontsize=12)
        ax.set_ylabel(ylabel, fontsize=12)
        ax.grid(True, linestyle='--', alpha=0.7)
        ax.legend(title='å¸‚å€¼ç»„åˆ«', fontsize=10)
        
        # è®¾ç½®æ—¥æœŸæ ¼å¼
        fig = ax.get_figure()
        fig.autofmt_xdate()
        
        # å¦‚æœæ˜¯ç™¾åˆ†æ¯”æ ¼å¼ï¼Œè®¾ç½®Yè½´æ ¼å¼
        if is_percentage:
            ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0%}'))
            
    except Exception as e:
        logger.error(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {str(e)}")
        raise

# åº”ç”¨å·²ç»åŒ…å«ä¼˜åŒ–åçš„calculate_metricå‡½æ•°å®šä¹‰

# ä¸»å†…å®¹åŒºåŸŸ
with main_content:
    st.header("Aè‚¡å¸‚åœºè§„æ¨¡æ•ˆåº”ç ”ç©¶")
    st.write("""
    æœ¬åº”ç”¨å±•ç¤ºäº†Aè‚¡å¸‚åœºä¸åŒå¸‚å€¼ç»„åˆ«(å°å¸‚å€¼åˆ°å¤§å¸‚å€¼)çš„æŠ•èµ„è¡¨ç°æŒ‡æ ‡.
    é€šè¿‡é€‰æ‹©ä¸åŒçš„ç»„åˆ«,æ—¶é—´èŒƒå›´å’ŒæŒ‡æ ‡ç±»å‹,å¯ä»¥è¿›è¡Œå¤šè§’åº¦çš„è§„æ¨¡æ•ˆåº”åˆ†æ.
    """)
    
    # æ·»åŠ åº”ç”¨è¯´æ˜å’Œæç¤º
    st.info("ğŸ’¡ æç¤º: æœ¬åº”ç”¨å·²é’ˆå¯¹Streamlit Cloudéƒ¨ç½²è¿›è¡Œäº†ä¼˜åŒ–ï¼ŒåŒ…å«å…¨é¢çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿ç¨³å®šè¿è¡Œã€‚")
    
    # æ˜¾ç¤ºæ•°æ®çŠ¶æ€ä¿¡æ¯
    if data is not None and not data.empty:
        st.success(f"âœ… æ•°æ®å·²åŠ è½½: å…± {len(data)} æ¡è®°å½•")
        if 'trade_date' in data.columns:
            try:
                min_date = data['trade_date'].min()
                max_date = data['trade_date'].max()
                st.info(f"ğŸ“… æ•°æ®æ—¥æœŸèŒƒå›´: {min_date.strftime('%Y-%m-%d')} è‡³ {max_date.strftime('%Y-%m-%d')}")
            except Exception as date_error:
                logger.warning(f"æ—¥æœŸæ˜¾ç¤ºé”™è¯¯: {str(date_error)}")
    
    # æ˜¾ç¤ºåˆ†ææŒ‰é’®
    if st.button("å¼€å§‹åˆ†æ", use_container_width=True):
        # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†åˆ†ç»„
        if not selected_groups:
            st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå¸‚å€¼ç»„åˆ«")
        else:
            try:
                # åŠ è½½æ•°æ®
                with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                    data, _ = load_group_data()
                    
                if data is not None and not data.empty:
                    # æ ¹æ®é€‰æ‹©çš„æ—¶é—´èŒƒå›´è¿‡æ»¤æ•°æ®
                    with st.spinner("æ­£åœ¨ç­›é€‰æ•°æ®..."):
                        filtered_data = filter_data_by_time(data, start_date, end_date)
                    
                    # æ£€æŸ¥è¿‡æ»¤åçš„æ•°æ®
                    if filtered_data is None or filtered_data.empty:
                        st.warning("âš ï¸ è¿‡æ»¤åçš„æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®è¿›è¡Œåˆ†æ")
                        filtered_data = data
                    
                    st.success(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå·²é€‰æ‹© {len(selected_groups)} ä¸ªåˆ†ç»„è¿›è¡Œåˆ†æ")
                    
                    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
                    st.subheader("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
                    stats_container = st.container()
                    with stats_container:
                        col1, col2, col3 = st.columns(3)
                        col1.metric("æ€»æ•°æ®é‡", len(filtered_data))
                        col2.metric("æ»šåŠ¨çª—å£å¤§å°", f"{window_size} ä¸ªæœˆ")
                        
                        # å®‰å…¨åœ°æ˜¾ç¤ºæ—¶é—´èŒƒå›´
                        try:
                            if 'trade_date' in filtered_data.columns:
                                min_date_val = filtered_data['trade_date'].min()
                                max_date_val = filtered_data['trade_date'].max()
                                col3.metric("æ—¶é—´è·¨åº¦", f"{min_date_val.strftime('%Y-%m')} è‡³ {max_date_val.strftime('%Y-%m')}")
                            else:
                                col3.metric("æ—¶é—´è·¨åº¦", "ä¸å¯ç”¨")
                        except Exception as date_error:
                            logger.warning(f"æ—¥æœŸç»Ÿè®¡é”™è¯¯: {str(date_error)}")
                            col3.metric("æ—¶é—´è·¨åº¦", "è®¡ç®—é”™è¯¯")
                    
                    # æ˜¾ç¤ºå‰5è¡Œæ•°æ®ä½œä¸ºæ ·ä¾‹
                    st.subheader("ğŸ“‹ æ•°æ®æ ·ä¾‹")
                    st.dataframe(filtered_data.head())
                    
                    # æŒ‡æ ‡è®¡ç®—å’Œå¯è§†åŒ–
                    for metric_display in selected_metrics:
                        metric_key = metrics_options[metric_display]
                        
                        st.subheader(f"ğŸ“ˆ {metric_display} åˆ†æ")
                        
                        # è®¡ç®—æŒ‡æ ‡
                        with st.spinner(f"æ­£åœ¨è®¡ç®—{metric_display}..."):
                            try:
                                result_data = calculate_time_series_metrics(
                                    filtered_data, selected_groups, metric_key, window_size
                                )
                                
                                if result_data is not None and not result_data.empty:
                                    st.success(f"âœ… {metric_display} è®¡ç®—å®Œæˆ")
                                    
                                    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
                                    st.write(f"è®¡ç®—äº† {len(result_data)} ä¸ªæ—¶é—´ç‚¹çš„{metric_display}")
                                    
                                    # è®¡ç®—æ¯ä¸ªåˆ†ç»„çš„å¹³å‡å€¼
                                    st.subheader("ğŸ† æŒ‡æ ‡å¹³å‡å€¼")
                                    try:
                                        avg_values = result_data.mean()
                                        avg_df = pd.DataFrame({
                                            "å¹³å‡å€¼": avg_values,
                                            "æ’å": avg_values.rank(ascending=metric_key != "volatility")
                                        })
                                        
                                        # æ ¼å¼åŒ–æ˜¾ç¤º
                                        if metric_key in ["monthly_return", "annual_return"]:
                                            avg_df["å¹³å‡å€¼"] = avg_df["å¹³å‡å€¼"].apply(lambda x: f"{x:.2%}")
                                        elif metric_key == "volatility":
                                            avg_df["å¹³å‡å€¼"] = avg_df["å¹³å‡å€¼"].apply(lambda x: f"{x:.2%}")
                                        elif metric_key == "sharpe":
                                            avg_df["å¹³å‡å€¼"] = avg_df["å¹³å‡å€¼"].apply(lambda x: f"{x:.2f}")
                                        
                                        st.dataframe(avg_df)
                                    except Exception as calc_error:
                                        logger.error(f"è®¡ç®—å¹³å‡å€¼æ—¶å‡ºé”™: {str(calc_error)}")
                                        st.warning("âš ï¸ æ— æ³•è®¡ç®—æŒ‡æ ‡å¹³å‡å€¼ï¼Œä½†å°†ç»§ç»­æ˜¾ç¤ºå›¾è¡¨")
                                    
                                    # ç»˜åˆ¶å›¾è¡¨
                                    st.subheader(f"ğŸ“Š {metric_display} æ—¶é—´åºåˆ—å›¾")
                                    
                                    try:
                                        # ä½¿ç”¨plotlyç»˜åˆ¶äº¤äº’å¼å›¾è¡¨
                                        import plotly.graph_objects as go
                                        
                                        fig = go.Figure()
                                        
                                        # ä¸ºæ¯ä¸ªåˆ†ç»„æ·»åŠ æŠ˜çº¿
                                        for group in result_data.columns:
                                            fig.add_trace(go.Scatter(
                                                x=result_data.index,
                                                y=result_data[group],
                                                mode='lines+markers',
                                                name=group,
                                                marker=dict(size=5),
                                                line=dict(width=2)
                                            ))
                                        
                                        # è®¾ç½®å›¾è¡¨å±æ€§
                                        fig.update_layout(
                                            title={
                                                'text': f'{metric_display} æ—¶é—´åºåˆ—æ¯”è¾ƒ',
                                                'font': {'size': 18, 'weight': 'bold'}
                                            },
                                            xaxis_title='æ—¥æœŸ',
                                            yaxis_title=metric_display,
                                            legend_title='å¸‚å€¼ç»„åˆ«',
                                            hovermode='x unified',
                                            template='plotly_white',
                                            # é»˜è®¤é«˜åº¦å·²ä¼˜åŒ–ä¸º700åƒç´ ï¼Œæ”¯æŒé¼ æ ‡æ»šè½®ç¼©æ”¾
                                            margin=dict(l=60, r=60, t=60, b=60)
                                        )
                                        
                                        # æ ¹æ®æŒ‡æ ‡ç±»å‹è®¾ç½®Yè½´æ ¼å¼
                                        if metric_key in ["monthly_return", "annual_return", "volatility"]:
                                            fig.update_layout(
                                                yaxis=dict(
                                                    tickformat='.1%'
                                                )
                                            )
                                        
                                        # æ˜¾ç¤ºå›¾è¡¨ï¼Œå¢åŠ æ»šåŠ¨ä¿¡æ¯è¯´æ˜
                                        st.markdown("**æ³¨æ„:** æ»šåŠ¨æŒ‡æ ‡ï¼ˆå¹´åŒ–æ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡ã€å¤æ™®æ¯”ç‡ï¼‰åœ¨æ•°æ®å¼€å§‹é˜¶æ®µå¯èƒ½ä½¿ç”¨éƒ¨åˆ†çª—å£è®¡ç®—ï¼Œéšç€æ—¶é—´æ¨ç§»æ‰ä¼šä½¿ç”¨å®Œæ•´çª—å£å¤§å°ã€‚")
                                        st.plotly_chart(fig, use_container_width=True, config={
                                            'scrollZoom': True,  # ç¡®ä¿å¯ç”¨æ»šè½®ç¼©æ”¾
                                            'displayModeBar': True,
                                            'toImageButtonOptions': {
                                                'format': 'png',
                                                'filename': 'scale_effect_chart',
                                                'height': 700,
                                                'width': 1200,
                                                'scale': 2
                                            }
                                        })
                                        
                                    except Exception as plot_error:
                                        logger.error(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {str(plot_error)}")
                                        st.warning(f"âš ï¸ å›¾è¡¨ç»˜åˆ¶å¤±è´¥: {str(plot_error)}ï¼Œä½†å°†ç»§ç»­å¤„ç†å…¶ä»–æŒ‡æ ‡")
                                else:
                                    st.warning(f"âš ï¸ æ— æ³•è®¡ç®—{metric_display}æ•°æ®")
                            except Exception as metric_error:
                                logger.error(f"è®¡ç®—{metric_display}æ—¶å‡ºé”™: {str(metric_error)}")
                                st.warning(f"âš ï¸ è®¡ç®—{metric_display}æ—¶å‘ç”Ÿé”™è¯¯ï¼Œä½†å°†ç»§ç»­å¤„ç†å…¶ä»–æŒ‡æ ‡")
                        
                        st.divider()
                    
                    # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ç”¨äºæ€»è¯„åˆ†
                    metrics = calculate_time_series_metrics(filtered_data, selected_groups, metric=None, rolling_window=window_size)
                    
                    # æ˜¾ç¤ºæ€»è¯„åˆ†æŠ˜çº¿å›¾
                    st.subheader("ğŸ“Š æ€»è¯„åˆ†æŠ˜çº¿å›¾")
                    
                    # å®‰å…¨æ£€æŸ¥metricså’Œtotal_scores
                    if metrics is not None and 'total_scores' in metrics and metrics['total_scores'] is not None and not metrics['total_scores'].empty:
                        # åˆ›å»ºæ€»è¯„åˆ†å›¾è¡¨
                        fig = go.Figure()
                        
                        # ä¸ºæ¯ä¸ªåˆ†ç»„æ·»åŠ è¯„åˆ†çº¿
                        for group in selected_groups:
                            if group in metrics['total_scores'].columns:
                                # è®¡ç®—è¯¥åˆ†ç»„çš„è¯„åˆ†æ•°æ®
                                scores = metrics['total_scores'][group]
                                
                                # æ·»åŠ æŠ˜çº¿
                                fig.add_trace(go.Scatter(
                                    x=scores.index, 
                                    y=scores, 
                                    mode='lines+markers',
                                    name=group,
                                    line=dict(width=2),
                                    marker=dict(size=5, opacity=0.7)
                                ))
                        
                        # æ·»åŠ è¯„åˆ†å‡å€¼çº¿ï¼ˆä½œä¸ºå‚è€ƒï¼‰
                        avg_scores = metrics['total_scores'].mean(axis=1)
                        fig.add_trace(go.Scatter(
                            x=avg_scores.index, 
                            y=avg_scores, 
                            mode='lines',
                            name='å¹³å‡è¯„åˆ†',
                            line=dict(width=2, dash='dash', color='black'),
                            hoverinfo='skip',
                            legendrank=10  # ç¡®ä¿å‡å€¼çº¿åœ¨å›¾ä¾‹åº•éƒ¨
                        ))
                        
                        # è®¾ç½®å¸ƒå±€
                        fig.update_layout(
                            title='å„åˆ†ç»„æ€»è¯„åˆ†å˜åŒ–è¶‹åŠ¿',
                            xaxis_title='æ—¥æœŸ',
                            yaxis_title='è¯„åˆ† (0-100)',
                            legend_title='åˆ†ç»„',
                            hovermode='x unified',
                            template='plotly_white',
                            height=600,
                            margin=dict(l=60, r=40, t=60, b=40),
                            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                        )
                        
                        # è®¾ç½®Yè½´èŒƒå›´
                        fig.update_yaxes(range=[0, 100])
                        
                        # æ·»åŠ å‚è€ƒçº¿
                        fig.add_hline(y=50, line_dash="dot", line_color="gray", opacity=0.5)
                        
                        # æ˜¾ç¤ºå›¾è¡¨
                        st.plotly_chart(fig, use_container_width=True, config={
                            'scrollZoom': True,
                            'displayModeBar': True,
                            'toImageButtonOptions': {
                                'format': 'png',
                                'filename': 'scale_effect_scores',
                                'height': 600,
                                'width': 1200,
                                'scale': 2
                            }
                        })
                        
                        # æ·»åŠ è¯„åˆ†è¯´æ˜
                        st.markdown("### è¯„åˆ†è¯´æ˜")
                        st.markdown("- æ€»è¯„åˆ†åŸºäºä¸‰ä¸ªæ ¸å¿ƒæŠ•èµ„æŒ‡æ ‡åŠ æƒè®¡ç®—ï¼Œä½“ç°å…¨é¢çš„æŠ•èµ„ä»·å€¼è¯„ä¼°ï¼š")
                        st.markdown("  - **æ”¶ç›Šç‡(30%)**ï¼šè¡¡é‡æŠ•èµ„å›æŠ¥æ°´å¹³ï¼Œæ”¶ç›Šç‡è¶Šé«˜è¯„åˆ†è¶Šé«˜")
                        st.markdown("  - **æ³¢åŠ¨ç‡(20%)**ï¼šè¡¡é‡é£é™©æ°´å¹³ï¼Œæ³¢åŠ¨ç‡è¶Šä½è¯„åˆ†è¶Šé«˜ï¼Œé«˜æ³¢åŠ¨ç‡ä¼šå—åˆ°é¢å¤–æƒ©ç½š")
                        st.markdown("  - **å¤æ™®æ¯”ç‡(50%)**ï¼šè¡¡é‡é£é™©è°ƒæ•´åå›æŠ¥ï¼Œæ˜¯æœ€é‡è¦çš„ç»¼åˆæŒ‡æ ‡ï¼Œè´Ÿå¤æ™®æ¯”ç‡ä¼šå—åˆ°é¢å¤–æƒ©ç½š")
                        st.markdown("- è¯„åˆ†èŒƒå›´ï¼š0-100ï¼Œ**åˆ†å€¼è¶Šé«˜è¡¨ç¤ºç»¼åˆè¡¨ç°è¶Šå¥½**ï¼Œåæ˜ æŠ•èµ„ç»„åˆçš„è´¨é‡")
                        st.markdown("- é»‘è‰²è™šçº¿è¡¨ç¤ºæ‰€æœ‰åˆ†ç»„çš„å¹³å‡è¯„åˆ†ï¼Œå¯ä½œä¸ºå¸‚åœºåŸºå‡†å‚è€ƒ")
                        
                        # æ˜¾ç¤ºæœ€æ–°è¯„åˆ†ç»Ÿè®¡
                        st.markdown("### æœ€æ–°è¯„åˆ†ç»Ÿè®¡")
                        latest_scores = metrics['total_scores'].iloc[-1]
                        best_score_group = latest_scores.idxmax()
                        best_score_value = latest_scores.max()
                        
                        st.markdown(f"- **æœ€ä½³è¯„åˆ†:** {best_score_group}ï¼Œè¯„åˆ†å€¼: {best_score_value:.1f}")
                        
                        # è®¡ç®—è¯„åˆ†æ’å
                        sorted_scores = latest_scores.sort_values(ascending=False)
                        ranking_df = pd.DataFrame({
                            'åˆ†ç»„': sorted_scores.index,
                            'è¯„åˆ†': sorted_scores.values
                        }).round(1)
                        
                        # æ˜¾ç¤ºæ’åè¡¨æ ¼
                        st.dataframe(ranking_df, use_container_width=True, hide_index=True)
                    else:
                        st.warning("æ— æ³•è®¡ç®—æ€»è¯„åˆ†æ•°æ®")
                    

                    
                else:
                    st.error("âŒ æ— æ³•åŠ è½½æ•°æ®æˆ–æ•°æ®ä¸ºç©º")
                    # å¦‚æœæœ¬åœ°å¼€å‘ç¯å¢ƒï¼Œæ˜¾ç¤ºæ›´å¤šè°ƒè¯•ä¿¡æ¯
                    if IS_LOCAL:
                        st.info("å¼€å‘ç¯å¢ƒè°ƒè¯•ä¿¡æ¯:")
                        st.info(f"æ•°æ®ç›®å½•: {DATA_DIR}")
                        st.info(f"ç›®å½•å†…å®¹: {os.listdir(DATA_DIR) if os.path.exists(DATA_DIR) else 'ç›®å½•ä¸å­˜åœ¨'}")
                    
            except Exception as e:
                logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
                st.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                # å¦‚æœæ˜¯æœ¬åœ°å¼€å‘ç¯å¢ƒï¼Œæ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                if IS_LOCAL:
                    st.exception(e)
                else:
                    st.info("å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æˆ–æŸ¥çœ‹åº”ç”¨æ—¥å¿—")